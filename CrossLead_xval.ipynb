{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from spacy.en import English\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_text = pd.read_csv('data_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a list of stopwords, remove 'the', because I'm interested in specificity. \n",
    "\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "#STOPLIST.remove('the')\n",
    "# Remove symbols that are not alpha-numeric, replace them with a space\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformer that cleans text with spaCy\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert text to cleaned text\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that cleans text:\n",
    "def cleanText(text):\n",
    "    # get rid of newlines, and non alpha-numeric characters\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', ' ', text)\n",
    "    text = re.sub(' +',' ',text)   \n",
    "\n",
    "\n",
    "\n",
    "    #parse it\n",
    "    parsed_text = nlp(text)\n",
    "\n",
    "    # get rid of proper nouns\n",
    "    proper = []\n",
    "    token_isoov = [token.is_oov for token in parsed_text]\n",
    "    token_text = [token.orth_ for token in parsed_text]\n",
    "    token_pos = [token.pos_ for token in parsed_text]\n",
    "    for pos, word, oov in zip(token_pos,token_text,token_isoov):\n",
    "        if pos == 'PROPN' and oov==True:\n",
    "            proper.append(str(word))\n",
    "    for pro in proper:\n",
    "        text = text.replace(pro,' PROPN ')\n",
    "\n",
    "\n",
    "    #recode entities\n",
    "    ents = {}\n",
    "    for num,entity in enumerate(parsed_text.ents):\n",
    "        ents[entity.label_] = entity.orth_\n",
    "    for code, entity in ents.items():\n",
    "        text = text.replace(entity,str(' '+code+' '))\n",
    "        \n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub(' +',' ',text)  \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A custom function to tokenize the text using spaCy\n",
    "# and convert to lemmas\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenizeText, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test = train_test_split(data_text.X,data_text.Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "Nearest Neighbors 0.528183716075\n",
      "----------------------------------------------------------------------------------------------\n",
      "Linear SVM 0.434237995825\n",
      "----------------------------------------------------------------------------------------------\n",
      "RBF SVM 0.615866388309\n",
      "----------------------------------------------------------------------------------------------\n",
      "Decision Tree 0.441196938065\n",
      "----------------------------------------------------------------------------------------------\n",
      "Random Forest 0.443980514962\n",
      "----------------------------------------------------------------------------------------------\n",
      "Neural Net 0.6040361865\n",
      "----------------------------------------------------------------------------------------------\n",
      "AdaBoost 0.523312456507\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c8468924af25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mclf_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleanText'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCleanTextTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'vectorizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mpreds_bow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------------------------------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marleneguraieb/anaconda2/envs/python3_env/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marleneguraieb/anaconda2/envs/python3_env/lib/python3.5/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, store_covariances, tol)\u001b[0m\n\u001b[1;32m    663\u001b[0m                           DeprecationWarning)\n\u001b[1;32m    664\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marleneguraieb/anaconda2/envs/python3_env/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/marleneguraieb/anaconda2/envs/python3_env/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 380\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marleneguraieb/anaconda2/envs/python3_env/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \"\"\"\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    244\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "          \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "#    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf_p = clf\n",
    "    pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf_p)])\n",
    "    pipe.fit(train, labels_train)\n",
    "    preds_bow = pipe.predict(test)\n",
    "    print(\"----------------------------------------------------------------------------------------------\")\n",
    "    print(name,accuracy_score(labels_test, preds_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "0.1 1 0.459290187891\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.1 2 0.453027139875\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.1 3 0.443980514962\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.1 4 0.442588726514\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.1 5 0.439805149617\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.2 1 0.494780793319\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.2 2 0.480167014614\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.2 3 0.473903966597\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.2 4 0.472512178149\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.2 5 0.472512178149\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.3 1 0.519137091162\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.3 2 0.489213639527\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.3 3 0.482254697286\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.3 4 0.478775226166\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.3 5 0.478079331942\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.4 1 0.549060542797\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.4 2 0.505219206681\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.4 3 0.491997216423\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.4 4 0.487821851079\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.4 5 0.487821851079\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.5 1 0.575504523312\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.5 2 0.535142658316\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.5 3 0.503827418232\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.5 4 0.494084899095\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.5 5 0.490605427975\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.6 1 0.600556715379\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.6 2 0.563674321503\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.6 3 0.540709812109\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.6 4 0.538622129436\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.6 5 0.538622129436\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.7 1 0.611691022965\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.7 2 0.583159359777\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.7 3 0.551844119694\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.7 4 0.540709812109\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.7 5 0.540013917884\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.8 1 0.621433542102\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.8 2 0.597773138483\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.8 3 0.564370215727\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.8 4 0.560194850383\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.8 5 0.557411273486\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.9 1 0.630480167015\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.9 2 0.606819763396\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.9 3 0.57341684064\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.9 4 0.561586638831\n",
      "----------------------------------------------------------------------------------------------\n",
      "0.9 5 0.558803061935\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.0 1 0.637439109255\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.0 2 0.615866388309\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.0 3 0.578288100209\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.0 4 0.565762004175\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.0 5 0.562282533055\n"
     ]
    }
   ],
   "source": [
    "C_2d_range = [i/10 for i in range(1,11)]\n",
    "gamma_2d_range = [i for i in range(1,6)]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf_p = SVC(C=C, gamma=gamma)\n",
    "        pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf_p)])\n",
    "        pipe.fit(train, labels_train)\n",
    "        preds_bow = pipe.predict(test)\n",
    "        classifiers.append((C, gamma, accuracy_score(labels_test, preds_bow)))\n",
    "        print(\"----------------------------------------------------------------------------------------------\")\n",
    "        print(C,gamma,accuracy_score(labels_test, preds_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650661099513 1.3 1\n"
     ]
    }
   ],
   "source": [
    "max_ = 0\n",
    "for (k, (C, gamma, score)) in enumerate(classifiers):\n",
    "    if score>max_:\n",
    "        max_ = score\n",
    "        C_ = C\n",
    "        Gamma = gamma\n",
    "print(max_,C_,Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.1 0.551844119694\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.2 0.593597773138\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.3 0.610299234516\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.4 0.620737647878\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.5 0.627000695894\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.6 0.633263743911\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.7 0.640222686152\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.8 0.642310368824\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 0.9 0.643702157272\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.1 1.0 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.1 0.55462769659\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.2 0.601252609603\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.3 0.617258176757\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.4 0.625608907446\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.5 0.636047320807\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.6 0.6416144746\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.7 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.8 0.645789839944\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 0.9 0.646485734168\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.2 1.0 0.648573416841\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.1 0.560890744607\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.2 0.606123869172\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.3 0.620737647878\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.4 0.632567849687\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.5 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.6 0.647181628392\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.7 0.646485734168\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.8 0.648573416841\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 0.9 0.651356993737\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.3 1.0 0.650661099513\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.1 0.569241475296\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.2 0.609603340292\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.3 0.62630480167\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.4 0.640222686152\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.5 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.6 0.645789839944\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.7 0.647877522617\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.8 0.650661099513\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 0.9 0.647877522617\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.4 1.0 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.1 0.57341684064\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.2 0.613778705637\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.3 0.631176061239\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.4 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.5 0.644398051496\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.6 0.647877522617\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.7 0.647877522617\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.8 0.645789839944\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 0.9 0.643702157272\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.5 1.0 0.643702157272\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.1 0.579679888657\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.2 0.618649965205\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.3 0.631871955463\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.4 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.5 0.646485734168\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.6 0.649269311065\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.7 0.650661099513\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.8 0.645789839944\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 0.9 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.6 1.0 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.1 0.589422407794\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.2 0.620737647878\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.3 0.642310368824\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.4 0.644398051496\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.5 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.6 0.646485734168\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.7 0.645789839944\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.8 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 0.9 0.642310368824\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.7 1.0 0.644398051496\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.1 0.591510090466\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.2 0.624217118998\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.3 0.642310368824\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.4 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.5 0.649965205289\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.6 0.647877522617\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.7 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.8 0.642310368824\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 0.9 0.643006263048\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.8 1.0 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.1 0.591510090466\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.2 0.629784272791\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.3 0.640222686152\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.4 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.5 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.6 0.646485734168\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.7 0.644398051496\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.8 0.640222686152\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 0.9 0.6416144746\n",
      "----------------------------------------------------------------------------------------------\n",
      "1.9 1.0 0.643702157272\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.1 0.594989561587\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.2 0.630480167015\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.3 0.639526791928\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.4 0.644398051496\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.5 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.6 0.64509394572\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.7 0.642310368824\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.8 0.6416144746\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 0.9 0.6416144746\n",
      "----------------------------------------------------------------------------------------------\n",
      "2.0 1.0 0.643702157272\n"
     ]
    }
   ],
   "source": [
    "C_2d_range = [1+i/10 for i in range(1,11)]\n",
    "gamma_2d_range = [i/10 for i in range(1,11)]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf_p = SVC(C=C, gamma=gamma)\n",
    "        pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf_p)])\n",
    "        pipe.fit(train, labels_train)\n",
    "        preds_bow = pipe.predict(test)\n",
    "        classifiers.append((C, gamma, accuracy_score(labels_test, preds_bow)))\n",
    "        print(\"----------------------------------------------------------------------------------------------\")\n",
    "        print(C,gamma,accuracy_score(labels_test, preds_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3_env]",
   "language": "python",
   "name": "conda-env-python3_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
